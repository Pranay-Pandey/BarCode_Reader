{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "\n",
    "def show_image(img):\n",
    "    \n",
    "    def img_Image():\n",
    "        total_image = Image.fromarray(img)\n",
    "        total_image.show()\n",
    "\n",
    "    t = Thread(target=img_Image)\n",
    "    t.start()\n",
    "\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r'Output\\0.png')\n",
    "image_original = image.copy()\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the image with bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply a threshold to the image to create a binary image\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # Draw the bounding rectangle on the original image\n",
    "    image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "\n",
    "# Find contours in the dilated binary image\n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in contours:\n",
    "    # Get the bounding rectangle of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # Draw the bounding rectangle on the original image\n",
    "    image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the image and convert it to grayscale\n",
    "image = cv2.imread('all barcode\\IMG_20220303_173611.jpg')\n",
    "image = image_original\n",
    "image = cv2.resize(image, None, fx=0.9, fy=0.9)\n",
    "\n",
    "ray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#Now convert the grayscale image to binary image\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv2.erode(binary,kernel,iterations = 2)\n",
    "\n",
    "\n",
    "#Now detect the contours\n",
    "contours, hierarchy = cv2.findContours(dilation, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#Visualize the data structure\n",
    "print(\"Length of contours {}\".format(len(contours)))\n",
    "# print(contours)\n",
    "\n",
    "# # Initialize an empty list to store the most external contours\n",
    "# most_external_contours = []\n",
    "\n",
    "# contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# # Iterate through each contour\n",
    "# for id,contour in enumerate(contours):\n",
    "#     if id==0:\n",
    "#         continue\n",
    "#     # Get the convex hull of the contour\n",
    "#     hull = cv2.convexHull(contour)\n",
    "#     epsilon = 0.1*cv2.arcLength(contour,True)\n",
    "#     approx = cv2.approxPolyDP(contour,epsilon,True)\n",
    "#     # Append the convex hull to the list of most external contours\n",
    "#     most_external_contours.append(approx)\n",
    "\n",
    "\n",
    "# Get the moments of the contours\n",
    "moments = [cv2.moments(c) for c in contours]\n",
    "\n",
    "# Filter out the invalid moments\n",
    "valid_moments = [m for m in moments if m[\"m00\"] != 0]\n",
    "\n",
    "# Get the centroid of each valid contour\n",
    "centroids = [(m[\"m10\"] / m[\"m00\"], m[\"m01\"] / m[\"m00\"]) for m in valid_moments]\n",
    "\n",
    "if len(centroids)==0:\n",
    "    raise ValueError(\"No valid contours found.\")\n",
    "\n",
    "# Convert the centroids to a numpy array\n",
    "centroids = np.array(centroids)\n",
    "\n",
    "# Apply KMeans clustering to group the contours into clusters\n",
    "kmeans = KMeans(n_clusters=3,random_state=0)\n",
    "kmeans.fit(centroids)\n",
    "\n",
    "# Get the labels of each contour\n",
    "labels = kmeans.labels_\n",
    "print(\"Length of labels = \", len(labels))\n",
    "\n",
    "# Create a list of lists, where each sublist contains the contours of a cluster\n",
    "clusters = [[] for _ in range(kmeans.n_clusters)]\n",
    "for i, c in enumerate(contours):\n",
    "    if i>=len(labels):\n",
    "        break\n",
    "    clusters[labels[i]].append(c)\n",
    "\n",
    "# # Find the outermost contour of each cluster\n",
    "# outer_contours = []\n",
    "# for cluster in clusters:\n",
    "#     x,y,w,h = cv2.boundingRect(np.array(cluster))\n",
    "#     outer_contours.append([x,y,w,h])\n",
    "\n",
    "# Find the outermost contour of each cluster\n",
    "outer_contours = []\n",
    "for cluster in clusters:\n",
    "    # Combine all the contours of the cluster into a single numpy array\n",
    "    cluster_contour = np.concatenate(cluster)\n",
    "    x,y,w,h = cv2.boundingRect(cluster_contour)\n",
    "    outer_contours.append([x,y,w,h])\n",
    "\n",
    "    \n",
    "# Draw the outermost contours on the image\n",
    "for oc in outer_contours:\n",
    "    x, y, w, h = oc\n",
    "    image_copy = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Draw the most external contours on the original image\n",
    "# image_copy = cv2.drawContours(image, most_external_contours, -1, (0, 255, 0), 100)\n",
    "\n",
    "# # Show the image with most external contours\n",
    "# cv2.imshow(\"Most external contours\", image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# # draw contours on the original image\n",
    "# image_copy = image.copy()\n",
    "# image_copy = cv2.drawContours(image_copy, contours, -1, (0, 255, 0), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(image_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_copy_again = cv2.resize(image_copy, None, fx=0.25, fy=0.25)\n",
    "cv2.imshow(\"ima\", image_copy_again)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOST EXTERNAL CONTOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the image and convert it to grayscale\n",
    "image = cv2.imread('all barcode\\IMG_20220303_175324.jpg')\n",
    "image = image_original\n",
    "image = cv2.resize(image, None, fx=0.9, fy=0.9)\n",
    "\n",
    "ray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#Now convert the grayscale image to binary image\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv2.erode(binary,kernel,iterations = 2)\n",
    "\n",
    "\n",
    "#Now detect the contours\n",
    "contours, hierarchy = cv2.findContours(dilation, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#Visualize the data structure\n",
    "print(\"Length of contours {}\".format(len(contours)))\n",
    "# print(contours)\n",
    "\n",
    "# Initialize an empty list to store the most external contours\n",
    "most_external_contours = []\n",
    "\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# Iterate through each contour\n",
    "for id,contour in enumerate(contours):\n",
    "    if id==0:\n",
    "        continue\n",
    "    # Get the convex hull of the contour\n",
    "    hull = cv2.convexHull(contour)\n",
    "    epsilon = 0.02*cv2.arcLength(contour,True)\n",
    "    approx = cv2.approxPolyDP(contour,epsilon,True)\n",
    "    # Append the convex hull to the list of most external contours\n",
    "    most_external_contours.append(approx)\n",
    "\n",
    "\n",
    "\n",
    "# Draw the most external contours on the original image\n",
    "image_copy = cv2.drawContours(image, most_external_contours, -1, (0, 255, 0), 2)\n",
    "# # Show the image with most external contours\n",
    "# cv2.imshow(\"Most external contours\", image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# # draw contours on the original image\n",
    "# image_copy = image.copy()\n",
    "# image_copy = cv2.drawContours(image_copy, contours, -1, (0, 255, 0), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(image_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy2 = cv2.resize(image_copy, None, fx=0.2, fy=0.2)\n",
    "cv2.imshow(\"img\",image_copy2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread(\"all barcode\\IMG_20220303_173611.jpg\")\n",
    "\n",
    "# Get the dimensions of the image\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# Define the output layers for YOLO\n",
    "layer_names = net.getLayerNames()\n",
    "print((net.getUnconnectedOutLayers()))\n",
    "# print(layer_names[])\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Construct a blob from the image\n",
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 16), swapRB=True, crop=False)\n",
    "\n",
    "# Perform a forward pass through the network\n",
    "net.setInput(blob)\n",
    "layer_outputs = net.forward([output_layers])\n",
    "\n",
    "# Initialize lists to store the bounding box coordinates and class IDs\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "# Iterate over the output layers\n",
    "for output in layer_outputs:\n",
    "    # Loop over the detections\n",
    "    for detection in output:\n",
    "        # Extract the class ID and confidence (i.e., probability) of the current object detection\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        # Filter out weak predictions by ensuring the detected probability is greater than the minimum probability\n",
    "        if confidence > 0.5:\n",
    "            # Scale the bounding box coordinates back relative to the size of the image\n",
    "            box = detection[0:4] * np.array([W, H, W, H])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "            # Use the center (x, y)-coordinates to derive the top and\n",
    "            # and left corner of the bounding box\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "\n",
    "            # Update the list of bounding box coordinates, confidences, and class IDs\n",
    "            boxes.append([x, y, int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Perform non-maximum suppression to suppress weak, overlapping bounding boxes\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "print(\"LEn of indices = \",len(indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "filename = 'all barcode\\IMG_20220303_173846.jpg'\n",
    "img = cv2.imread(filename)\n",
    "img = image_original\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[255,0,255]\n",
    "img_copy = cv2.resize(img, None, fx=0.3, fy = 0.3)\n",
    "cv2.imshow('dst',img_copy)\n",
    "if cv2.waitKey(0) & 0xff == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using clusters KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "filename = r'Output\\0.png'\n",
    "img = cv2.imread(filename)\n",
    "# img = image_original\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Find the coordinates of all corners\n",
    "coords = np.column_stack(np.where(dst > 0.01 * dst.max()))\n",
    "\n",
    "# Perform KMeans clustering on the corners\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(coords)\n",
    "\n",
    "extracted_images = []\n",
    "# Draw a bounding box around each cluster\n",
    "for i in range(kmeans.n_clusters):\n",
    "    # Get the coordinates of the current cluster\n",
    "    points = coords[kmeans.labels_ == i]\n",
    "\n",
    "    # Get minimum and maximum x,y coordinates of the points\n",
    "    xmin, ymin = np.min(points, axis=0)\n",
    "    xmax, ymax = np.max(points, axis=0)\n",
    "\n",
    "    # Draw a rectangle around the object\n",
    "    img = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # cluster_coords = coords[kmeans.labels_ == i]\n",
    "    # # Get the minimum and maximum coordinates of the cluster\n",
    "    # x_min, y_min = np.min(cluster_coords, axis=0)\n",
    "    # x_max, y_max = np.max(cluster_coords, axis=0)\n",
    "    # # Draw the bounding box\n",
    "    # cv2.rectangle(img, (y_min, x_min), (y_max, x_max), (0, 255, 0), 2)\n",
    "    # extracted_images.append(img[y_min:y_max,x_min:x_max])\n",
    "\n",
    "# for i in extracted_images:\n",
    "#     img_image = Image.fromarray(i)\n",
    "#     img_image.show()\n",
    "img_copy = cv2.resize(img, None, fx=0.2, fy = 0.2)\n",
    "cv2.imshow('image', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read image\n",
    "filename = 'all barcode\\IMG_20220303_173846.jpg'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create SIFT object\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "img = cv2.drawKeypoints(img, keypoints, img)\n",
    "\n",
    "# Cluster keypoints using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "clusters = kmeans.fit_predict(descriptors)\n",
    "\n",
    "# Find the bounding box for each cluster\n",
    "from collections import defaultdict\n",
    "cluster_points = defaultdict(list)\n",
    "for i, cluster in enumerate(clusters):\n",
    "    x, y = keypoints[i].pt\n",
    "    cluster_points[cluster].append((x, y))\n",
    "\n",
    "for cluster, points in cluster_points.items():\n",
    "    # Convert points to numpy array\n",
    "    points = np.array(points)\n",
    "    # Find the minimum and maximum x and y values\n",
    "    x_min, y_min = np.min(points, axis=0)\n",
    "    x_max, y_max = np.max(points, axis=0)\n",
    "    # Draw a bounding box\n",
    "    img = cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "\n",
    "# Show image\n",
    "img_copy = cv2.resize(img, None, fx=0.3, fy = 0.3)\n",
    "cv2.imshow('Image', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read in the image\n",
    "filename = 'all barcode\\IMG_20220303_173611.jpg'\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# Set up the detector with default parameters\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect blobs\n",
    "keypoints = detector.detect(img)\n",
    "\n",
    "# Draw bounding boxes around the blobs\n",
    "im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "img_copy = cv2.resize(im_with_keypoints, None , fx = 0.3, fy=0.3)\n",
    "# Show the image with bounding boxes\n",
    "cv2.imshow(\"Blobs\", img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster_from_corners(file_path, eps=140, min_samples=40):\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from PIL import Image\n",
    "\n",
    "    # Load image and detect corners\n",
    "    # filename = 'all barcode\\IMG_20220303_173611.jpg'\n",
    "    filename = file_path\n",
    "    img = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    width,height = img.shape[:2]\n",
    "\n",
    "    # Get coordinates of corners\n",
    "    coords = np.column_stack(np.where(dst > 0.01 * dst.max()))\n",
    "    img_temp = img.copy()\n",
    "    img_temp[dst>0.01*dst.max()]=[255,255,0]\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)\n",
    "\n",
    "    # Get labels for each corner\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    # print(n_clusters_)\n",
    "\n",
    "    extracted_images = []\n",
    "    # Draw bounding box around each cluster\n",
    "    for i in range(n_clusters_):\n",
    "        \n",
    "        # Get indexes of corners in current cluster\n",
    "        indexes = np.where(labels == i)\n",
    "\n",
    "        # Get coordinates of corners in current cluster\n",
    "        cluster_coords = coords[indexes]\n",
    "\n",
    "        # Get min and max x and y coordinates\n",
    "        min_x, min_y = np.min(cluster_coords, axis=0)\n",
    "        max_x, max_y = np.max(cluster_coords, axis=0)\n",
    "        if abs((max_x-min_x)*(max_y-min_y))/(width*height)<0.1:\n",
    "            continue\n",
    "\n",
    "        # # cnt = [min_x, min_y, max_x, max_y]\n",
    "        # # cnt = np.array(cnt)\n",
    "        # # epsilon = 0.1*cv2.arcLength(cluster_coords, True)\n",
    "        # # approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "        # # img = cv2.drawContours(img, [approx], -1, (0, 255, 0), 3)\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img, (min_y, min_x), (max_y, max_x), (0, 255, 0), 2)\n",
    "        print(\"area ratio = \",abs((max_x-min_x)*(max_y-min_y))/(width*height))\n",
    "\n",
    "\n",
    "        # # Using Convex Hull\n",
    "        # cluster_coords = coords[indexes]\n",
    "\n",
    "        # # Find the convex hull of the corners in the cluster\n",
    "        # hull = cv2.convexHull(cluster_coords)\n",
    "\n",
    "        # # Draw the convex hull as a polygon on the original image\n",
    "        # img = cv2.drawContours(img, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # # Using ApproxPolyDP\n",
    "        # # Get coordinates of corners in current cluster\n",
    "        # cluster_coords = coords[indexes]\n",
    "\n",
    "        # # find the perimeter of the object\n",
    "        # epsilon = 0.5*cv2.arcLength(cluster_coords, True)\n",
    "        # # approximate the object shape\n",
    "        # approx = cv2.approxPolyDP(cluster_coords, epsilon, True)\n",
    "\n",
    "        # # Draw the approximate shape on the original image\n",
    "        # img = cv2.drawContours(img, [approx], -1, (0, 255, 0), 4)\n",
    "\n",
    "\n",
    "        extracted_images.append(img[min_x:max_x,min_y:max_y])\n",
    "\n",
    "    # for id,ims in enumerate(extracted_images):\n",
    "    #     temp = Image.fromarray(ims)\n",
    "    #     temp.save(f'Output\\{id}.jpg')\n",
    "    # Show image\n",
    "\n",
    "    t = Thread(target=show_image, args=(img,))\n",
    "    t.start()\n",
    "    # img_temp_file = Image.fromarray(img_temp)\n",
    "    # img_temp_file.show()\n",
    "    # img_copy = cv2.resize(img, None, fx=0.3, fy = 0.3)\n",
    "    # cv2.imshow('image', img_copy)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return extracted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_from_corners(r'Output\\8.png')\n",
    "# import os\n",
    "# direc = 'Output'\n",
    "# for file in os.listdir(direc):\n",
    "#     fname = os.path.join(direc, file)\n",
    "#     Cluster_from_corners(fname, 140, 40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # Load image\n",
    "img = cv2.imread(r\"Output\\1.png\")\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# img2 = img.copy()\n",
    "\n",
    "# # Apply Canny edge detection\n",
    "# edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# # Find lines using HoughLinesP\n",
    "# lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# # Draw lines on image\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "#     cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# img2 = img.copy()\n",
    "# # Find and draw contours\n",
    "# contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# for contour in contours:\n",
    "#     epsilon = 0.1*cv2.arcLength(contour, True)\n",
    "#     approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "#     cv2.drawContours(img2, [approx], -1, (0, 0, 255), 2)\n",
    "import cv2\n",
    "\n",
    "# Load image\n",
    "# img = cv2.imread(r\"image.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "outer_contour = None\n",
    "# Iterate through contours\n",
    "for contour in contours:\n",
    "    # Approximate contour with a polygon\n",
    "    epsilon = 5*cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    # Check if the approximated contour is a closed loop\n",
    "    if len(approx) >= 4 and cv2.isContourConvex(approx):\n",
    "        # Draw approximated contour on the image\n",
    "        cv2.drawContours(img, [approx], -1, (0, 255, 0), 3)\n",
    "\n",
    "        # Find the outermost contour\n",
    "        if cv2.contourArea(approx) == max([cv2.contourArea(c) for c in contours]):\n",
    "            outer_contour = approx\n",
    "\n",
    "# Draw outermost contour on the image\n",
    "if (outer_contour):\n",
    "    cv2.drawContours(img, [outer_contour], -1, (255, 0, 0), 3)\n",
    "    t = Thread(target=show_image, args=(img,))\n",
    "    t.start()\n",
    "else:\n",
    "\n",
    "    print(\"NO outer contour\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological identifiaction on exracted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "for file in os.listdir('Output'):\n",
    "    imageFile = os.path.join('Output',file)\n",
    "    im = cv2.imread(imageFile)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Perform morphological opening (erosion followed by dilation)\n",
    "    opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Perform morphological closing (dilation followed by erosion)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Threshold the image to binary\n",
    "    ret, thresh = cv2.threshold(closing, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Count the number of non-zero pixels\n",
    "    non_zero_pixels = cv2.countNonZero(thresh)\n",
    "    print(file, \" = \", non_zero_pixels, \" pixels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLustering contours with DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas \n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
    "\n",
    "# Images\n",
    "img = 'all barcode\\IMG_20220303_173611.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "model.conf = 0.01  # confidence threshold (0-1)\n",
    "\n",
    "torch.device('cpu')\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "# results = model(img).detach().cpu().clone().numpy()\n",
    "\n",
    "# Results\n",
    "results.print() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, cord_thres = results.xyxyn[0][:, -1].numpy(), results.xyxyn[0][:, :-1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result['boxes']\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(f'Object Coordinates: ({x1}, {y1}), ({x2}, {y2})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.tensor\n",
    "boxes = results[0]\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    print(f'Object Coordinates: ({x1}, {y1}), ({x2}, {y2})')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultralytics Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# results = model(\"all barcode\\IMG_20220303_173846.jpg\")  # predict on an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmenation masks outputs\n",
    "    probs = result.probs  # Class probabilities for classification outputs\n",
    "    print(boxes.xyxy)\n",
    "    print(boxes.xyxy.shape)\n",
    "    \n",
    "    # print(\"probs= \",probs)\n",
    "    for box in boxes:\n",
    "\n",
    "        x1 , y1 , x2 , y2 = box.xyxy.detach().numpy()[0]\n",
    "        # print(x1 , y1 , x2 , y2 )\n",
    "        # print(box.conf.detach().numpy()[0])\n",
    "        # print(box.to)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to predict on image and draw bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "def detect_Yolo_object(filename, conf = 0.01, iou = 0.4, cutoff_factor = 3, print_output = True, show_output = True):\n",
    "    total_images = []\n",
    "    from ultralytics import YOLO\n",
    "    img = cv2.imread(filename)\n",
    "    ori_image = img.copy()\n",
    "    results = model(filename,conf=conf, iou=iou)  # predict on an image\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        for box in boxes:\n",
    "            x1 , y1 , x2 , y2 = box.xyxy.detach().numpy()[0]\n",
    "            if (abs(x1-x2)*abs(y1-y2)<img.shape[0]*img.shape[0]/cutoff_factor):\n",
    "                img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,255), 2)\n",
    "                img = cv2.putText(img, str(box.conf.detach().numpy()[0]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX\n",
    "                , fontScale=1, color = (255,0,0))\n",
    "                if print_output:\n",
    "                    print(box.conf.detach().numpy()[0])\n",
    "                total_images.append(ori_image[int(y1):int(y2),int(x1):int(x2)])\n",
    "            else:\n",
    "                img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 3)\n",
    "                img = cv2.putText(img, str(box.conf.detach().numpy()[0]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX\n",
    "                , fontScale=1, color = (0,0,255))\n",
    "                if print_output:\n",
    "                    print(\"left \",box.conf.detach().numpy()[0])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target=show_image, args=(img,))\n",
    "        t.start()\n",
    "    return total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'all barcode\\IMG_20220303_175539.jpg'\n",
    "all_images = detect_Yolo_object(filepath, 0.01, 0.5, print_output=False, show_output=True)\n",
    "# print(model.overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,im in enumerate(all_images):\n",
    "    im_pil = Image.fromarray(im)\n",
    "    im_pil.save(f\"Output/{id}.png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMS On bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NMS_detect_Yolo_object(filename, conf = 0.01, iou = 0.4, cutoff_factor = 3, print_output = True, show_output=False):\n",
    "    total_images = []\n",
    "    \n",
    "    img = cv2.imread(filename)\n",
    "    ori_image = img.copy()\n",
    "    results = model(filename,conf=conf, iou=iou)  # predict on an image\n",
    "\n",
    "    # NMS\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1 , y1 , x2 , y2 = box.xyxy.detach().numpy()[0]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            confidences.append(box.conf.detach().numpy()[0])\n",
    "\n",
    "    # convert boxes and confidences to numpy array\n",
    "    boxes = np.array(boxes)\n",
    "    confidences = np.array(confidences)\n",
    "\n",
    "    # NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf, iou)\n",
    "    indices = indices.flatten()\n",
    "\n",
    "    for i in indices:\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        if (abs(x1-x2)*abs(y1-y2)<img.shape[0]*img.shape[0]/cutoff_factor):\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,255), 2)\n",
    "            img = cv2.putText(img, str(confidences[i]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color = (255,0,0))\n",
    "            if print_output:\n",
    "                print(confidences[i])\n",
    "            total_images.append(ori_image[int(y1):int(y2),int(x1):int(x2)])\n",
    "        else:\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 3)\n",
    "            img = cv2.putText(img, str(confidences[i]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color = (0,0,255))\n",
    "            if print_output:\n",
    "                print(\"left \",confidences[i])\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target=show_image, args=(img,))\n",
    "        t.start()\n",
    "    return total_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'all barcode\\IMG_20220303_175324.jpg'\n",
    "NMS_detect_Yolo_object(filepath, show_output=True, print_output=True, conf = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'missing barcode\\IMG_20220303_175627.jpg'\n",
    "dir_name = 'all barcode'\n",
    "save_dir = 'Output'\n",
    "i = 0\n",
    "for file in os.listdir(dir_name):\n",
    "    filepath = os.path.join(dir_name,file)\n",
    "    all_images = NMS_detect_Yolo_object(filepath, 0.01, 0.5, cutoff_factor=2,print_output=False)\n",
    "    for ima in all_images:\n",
    "        pilImage = Image.fromarray(ima)\n",
    "        pilImage.save(f'{save_dir}/{i}.png')\n",
    "        i+=1\n",
    "\n",
    "# print(model.overrides)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Segmentation of the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(\"all barcode\\IMG_20220303_173611.jpg\", conf=0.01)  # predict on an image\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for res in results:\n",
    "    ak = np.array(res.masks.segments, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img = cv2.imread(\"all barcode\\IMG_20220303_173611.jpg\")\n",
    "width, he\n",
    "for res in results:\n",
    "    # print(res.masks.segments)\n",
    "    for points in res.boxes.xyxy.detach().numpy():\n",
    "        x1,y1,x2,y2 = points\n",
    "        temp_img = cv2.circle(temp_img, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "img = cv2.imread(\"all barcode\\IMG_20220303_173611.jpg\")  # read the image\n",
    "results = model(img, conf=0.01)  # predict on an image\n",
    "\n",
    "segmented_image = np.zeros_like(res.masks.pixels)\n",
    "\n",
    "for res in results:\n",
    "    boxes = res.boxes.xyxy.numpy()  # get the bounding boxes\n",
    "    masks = np.array(res.masks.segments)  # get the masks for each object\n",
    "            # Get the segments that correspond to the object of interest\n",
    "    object_mask = res.masks.segments == 1\n",
    "    object_indices = np.where(object_mask)\n",
    "\n",
    "    # Get the pixels of the object\n",
    "    object_pixels = res.masks.pixels[object_indices]\n",
    "\n",
    "    # Create a blank image with the same size as the input image\n",
    "    \n",
    "\n",
    "    # Draw the object on the blank image\n",
    "    cv2.fillPoly(segmented_image, [object_pixels], color=(255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(len(masks)):\n",
    "    #     mask = np.array(masks[i], dtype=np.uint8)  # convert the mask to a numpy array\n",
    "    #     mask = mask.astype(bool)\n",
    "    #     import numpy as np\n",
    "\n",
    "\n",
    "    #     img[:,:,0][mask] = np.random.randint(0,255)\n",
    "    #     img[:,:,1][mask] = np.random.randint(0,255)\n",
    "    #     img[:,:,2][mask] = np.random.randint(0,255)\n",
    "    #     cv2.rectangle(img, (int(boxes[i][0]), int(boxes[i][1])), (int(boxes[i][2]), int(boxes[i][3])), (0,255,255), 2)\n",
    "\n",
    "cv2.imshow(\"Segmented Image\", segmented_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing on YOLO Objects to draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def on_low_r_thresh_trackbar(val):\n",
    "    lower[0] = val\n",
    "def on_high_r_thresh_trackbar(val):\n",
    "    higher[0] = val\n",
    "def on_low_g_thresh_trackbar(val):\n",
    "    lower[1] = val\n",
    "def on_high_g_thresh_trackbar(val):\n",
    "    higher[1] = val\n",
    "def on_low_b_thresh_trackbar(val):\n",
    "    lower[2] = val\n",
    "def on_high_b_thresh_trackbar(val):\n",
    "    higher[2] = val\n",
    "\n",
    "def create_sliders():\n",
    "    cv2.namedWindow(\"Thresholds\")\n",
    "    cv2.createTrackbar(\"Low R\",\"Thresholds\",0,255,on_low_r_thresh_trackbar)\n",
    "    cv2.createTrackbar(\"High R\",\"Thresholds\",255,255,on_high_r_thresh_trackbar)\n",
    "    cv2.createTrackbar(\"Low G\",\"Thresholds\",0,255,on_low_g_thresh_trackbar)\n",
    "    cv2.createTrackbar(\"High G\",\"Thresholds\",255,255,on_high_g_thresh_trackbar)\n",
    "    cv2.createTrackbar(\"Low B\",\"Thresholds\",0,255,on_low_b_thresh_trackbar)\n",
    "    cv2.createTrackbar(\"High B\",\"Thresholds\",255,255,on_high_b_thresh_trackbar)\n",
    "\n",
    "def apply_mask(img):\n",
    "    mask = cv2.inRange(img, lower, higher)\n",
    "    cv2.imshow(\"masked\",mask)\n",
    "\n",
    "lower = np.array([60,60,60])\n",
    "higher = np.array([250,250,250])\n",
    "\n",
    "create_sliders()\n",
    "\n",
    "while True:\n",
    "    # load image\n",
    "    img = cv2.imread(r\"Output\\0.png\")\n",
    "    apply_mask(img)\n",
    "    cv2.imshow(\"Original\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(r\"Output\\0.png\")\n",
    "\n",
    "lower = np.array([135,75 ,0])\n",
    "higher = np.array([243,222,224])\n",
    "\n",
    "mask = cv2.inRange(img, lower, higher)\n",
    "\n",
    "cont, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cont_img = cv2.drawContours(img, cont, -1, 255, 3)\n",
    "\n",
    "\n",
    "# Show the image\n",
    "cv2.imshow(\"Outer Boundary\", cont_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Barcode Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = 0\n",
    "import cv2\n",
    "import numpy as np\n",
    "# load the image and convert it to grayscale\n",
    "image = cv2.imread(r\"Input_Images\\all barcode\\IMG_20220303_173611.jpg\")\n",
    "\n",
    "#resize image\n",
    "image = cv2.resize(image,None,fx=0.7, fy=0.7, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#calculate x & y gradient\n",
    "gradX = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
    "gradY = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
    "\n",
    "# subtract the y-gradient from the x-gradient\n",
    "gradient = cv2.subtract(gradX, gradY)\n",
    "gradient = cv2.convertScaleAbs(gradient)\n",
    "if show == 1:\n",
    "\tcv2.imshow(\"gradient-sub\",cv2.resize(gradient,None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC))\n",
    "\n",
    "# blur the image\n",
    "blurred = cv2.blur(gradient, (3, 3))\n",
    "\n",
    "# threshold the image\n",
    "(_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if show == 1:\n",
    "\tcv2.imshow(\"threshed\",cv2.resize(thresh,None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC))\n",
    "\n",
    "# construct a closing kernel and apply it to the thresholded image\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 7))\n",
    "closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "if show == 1:\n",
    "\tcv2.imshow(\"morphology\",cv2.resize(closed,None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC))\n",
    "\n",
    "# perform a series of erosions and dilations\n",
    "closed = cv2.erode(closed, None, iterations = 4)\n",
    "closed = cv2.dilate(closed, None, iterations = 4)\n",
    "\n",
    "if show == 1:\n",
    "\tcv2.imshow(\"erode/dilate\",cv2.resize(closed,None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC))\n",
    "\n",
    "# find the contours in the thresholded image, then sort the contours\n",
    "# by their area, keeping only the largest one\n",
    "cnts,hierarchy = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "c = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "c1 = sorted(cnts, key = cv2.contourArea, reverse = True)[1]\n",
    "\n",
    "# compute the rotated bounding box of the largest contour\n",
    "rect = cv2.minAreaRect(c)\n",
    "box = np.int0(cv2.boxPoints(rect))\n",
    "rect1 = cv2.minAreaRect(c1)\n",
    "box1 = np.int0(cv2.boxPoints(rect1))\n",
    "\n",
    "# draw a bounding box arounded the detected barcode and display the\n",
    "# image\n",
    "cv2.drawContours(image, [box], -1, (0, 255, 0), 3)\n",
    "cv2.drawContours(image, [box1], -1, (0, 255, 0), 3)\n",
    "\n",
    "image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "t = Thread(target=show_image, args=(image,))\n",
    "t.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTEMPT 2\n",
    "import os\n",
    "import argparse\n",
    "import zbar\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess(image):\n",
    "\t# load the image\n",
    "\t#resize image\n",
    "\timage = cv2.resize(image,None,fx=0.7, fy=0.7, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "\t#convert to grayscale\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#calculate x & y gradient\n",
    "\tgradX = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
    "\tgradY = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
    "\n",
    "\t# subtract the y-gradient from the x-gradient\n",
    "\tgradient = cv2.subtract(gradX, gradY)\n",
    "\tgradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "\t# blur the image\n",
    "\tblurred = cv2.blur(gradient, (3, 3))\n",
    "\n",
    "\t# threshold the image\n",
    "\t(_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\n",
    "\tthresh = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\treturn thresh\n",
    "\n",
    "\t\n",
    "def barcode(image):\n",
    "\t# create a reader\n",
    "\tscanner = zbar.ImageScanner()\n",
    "\t\n",
    "\t# configure the reader\n",
    "\tscanner.parse_config('enable')\n",
    "\t\n",
    "\t# obtain image data\n",
    "\twidth, height = image.shape\n",
    "\traw = image.tobytes()\n",
    "\n",
    "\timage = zbar.Image(width, height, 'Y800', raw)\n",
    "\n",
    "\t# scan the image for barcodes\n",
    "\tscanner.scan(image)\n",
    "\t\n",
    "\t# extract results\n",
    "\tfor symbol in image:\n",
    "\t    # do something useful with results\n",
    "\t    print('format:', symbol.type, '| data:', '\"%s\"' % symbol.data)\n",
    "\t# clean up\n",
    "\tprint('-----------------------------------------------------------------------')\n",
    "\tdel(image)\n",
    "\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "bardet = cv2.QRCodeDetector()\n",
    "img = cv2.imread(r\"all barcode\\IMG_20220303_173611.jpg\")\n",
    "ok, decoded_info, decoded_type = bardet.detectAndDecode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzbar.pyzbar as pyzbar\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(r\"all barcode\\IMG_20220303_173611.jpg\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Enhance image quality\n",
    "gray = cv2.medianBlur(gray, 5)\n",
    "gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "# Detect barcodes\n",
    "barcodes = pyzbar.decode(gray)\n",
    "\n",
    "# Barcode information to return\n",
    "information = []\n",
    "\n",
    "# Iterate over detected barcodes\n",
    "for barcode in barcodes:\n",
    "    # Extract barcode data and type\n",
    "    barcodeData = barcode.data.decode(\"utf-8\")\n",
    "    barcodeType = barcode.type\n",
    "\n",
    "    # Draw barcode bounding box on image\n",
    "    (x, y, w, h) = barcode.rect\n",
    "    image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Info packet to return\n",
    "    information.append([x, y, x+w , y+h, barcodeData])\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "\n",
    "from BarcodeDetector import BarcodeDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attemp 4\n",
    "# importing sys\n",
    "import sys\n",
    "import cv2\n",
    " \n",
    " \n",
    "# adding Folder_2/subfolder to the system path\n",
    "sys.path.insert(0, r'repos\\barcode-runners-recognizer')\n",
    "\n",
    "from BarcodeDetector import BarcodeDetector\n",
    "from BarcodeRecognizer import BarcodeRecognizer\n",
    "\n",
    "\n",
    "\n",
    "detector = BarcodeDetector(useDebugMode=True)\n",
    "imageProcessed, boxes= detector.processImage(r\"all barcode\\IMG_20220303_175324.jpg\")\n",
    "recognizer = BarcodeRecognizer()\n",
    "for box in boxes:\n",
    "    print(box)\n",
    "    valid, code = recognizer.reconize(box)\n",
    "    if valid:\n",
    "        print(\"Code recognized: {}\".format(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approch 5\n",
    "from pylibdmtx.pylibdmtx import decode\n",
    "from PIL import Image\n",
    "\n",
    "decode(Image.open(r\"all barcode\\IMG_20220303_173611.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from PIL import Image\n",
    "def show_image(img):\n",
    "    def sh():\n",
    "        total_image = Image.fromarray(img)\n",
    "        total_image.show()\n",
    "    t=Thread(target=sh)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approch 6\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pyzbar.pyzbar import decode\n",
    " \n",
    "img = cv2.imread(r'all barcode\\IMG_20220303_173846.jpg')\n",
    "\n",
    "for barcode in decode(img):\n",
    "    myData = barcode.data.decode('utf-8')\n",
    "    # print(myData)\n",
    "\n",
    "\n",
    "    myColor = (0, 0, 255)\n",
    "\n",
    "    pts = np.array([barcode.polygon],np.int32)\n",
    "    print(pts)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    cv2.polylines(img,[pts],True,myColor,5)\n",
    "    pts2 = barcode.rect\n",
    "    # cv2.putText(img,myData,(pts2[0],pts2[1]),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    #             0.9,myColor,2)\n",
    "\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 6.2\n",
    "img_file_loc = r\"Input_Images\\all barcode\\IMG_20220303_173611.jpg\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "img = cv2.imread(img_file_loc)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply morphological operations to improve the quality of the image\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "closing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Detect lines in the image\n",
    "edges = cv2.Canny(closing, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "\n",
    "# Draw the lines in the image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Decode the barcode\n",
    "for barcode in decode(img):\n",
    "    myData = barcode.data.decode('utf-8')\n",
    "    myColor = (0, 0, 255)\n",
    "    pts = np.array([barcode.polygon], np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.polylines(img, [pts], True, myColor, 5)\n",
    "    pts2 = barcode.rect\n",
    "    cv2.putText(img, myData, (pts2[0], pts2[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.9, myColor, 2)\n",
    "\n",
    "# Show the processed image\n",
    "show_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!del license_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbr import *\n",
    "import cv2\n",
    "\n",
    "image = r\"Input_Images\\all barcode\\IMG_20220303_173611.jpg\"\n",
    "\n",
    "# BarcodeReader.init_license(license_key)\n",
    "\n",
    "reader = BarcodeReader()\n",
    "points = []\n",
    "text = ''\n",
    "try:\n",
    "   text_results = reader.decode_file(image)\n",
    "\n",
    "   if text_results != None:\n",
    "      for text_result in text_results:\n",
    "            text = text_result.barcode_text\n",
    "            points = text_result.localization_result.localization_points\n",
    "            \n",
    "except BarcodeReaderError as bre:\n",
    "   print(bre)\n",
    "\n",
    "pts = np.array(points, np.int32)\n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "# print(points)\n",
    "img = cv2.imread(image)\n",
    "cv2.polylines(img, [pts], True, (0, 0, 255), 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shadows make it dificult to perform object detection\n",
    "def remove_shadows(image):      \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a morphological opening operation to remove the shadows\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Subtract the opened image from the original grayscale image to obtain the shadow mask\n",
    "    shadow_mask = cv2.subtract(gray, opened)\n",
    "    \n",
    "    # Threshold the shadow mask to get the shadow pixels\n",
    "    _, thresh = cv2.threshold(shadow_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the shadow mask\n",
    "    thresh = 255 - thresh\n",
    "    \n",
    "    # Multiply the inverted shadow mask with the original image to remove the shadows\n",
    "    shadow_removed = cv2.bitwise_and(image, image, mask=thresh)\n",
    "    \n",
    "    return shadow_removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing bounding boxes on objects function\n",
    "import cv2\n",
    "def draw_boxes(image, points_list, color=(0,0,255), thickness=2):\n",
    "    if (type(image)==str):\n",
    "        image = cv2.imread(image)\n",
    "    for point in points_list:\n",
    "        x1,y1,x2,y2 = point\n",
    "        image = cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)),color, thickness)\n",
    "    return image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the image to the original Image\n",
    "\n",
    "Outline:\n",
    "\n",
    "    1. Use YOLO Object detection to braodly identify the different objects in the Image\n",
    "    2. On each object detected, find corners, cluster them and draw bounding box on the object\n",
    "    3. Later use this image to identify any Barcode \n",
    "\n",
    "Implementation till now :\n",
    "\n",
    "    1. Use NMS_detect_Yolo_object to extract all the identified objects in the form of an array\n",
    "    2. Use Cluster_from_corners function to extract all the bounding box on from the image\n",
    "\n",
    "TO DO:\n",
    "\n",
    "    1. Using NMS_detect_Yolo_object function make a function to extract the bounding box coordinates\n",
    "    2. Using Cluster_from_corners make a function to extract the bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "import pyzbar.pyzbar as pyzbar\n",
    "from dbr import *\n",
    "import matplotlib.path as mplPath\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    total_image = Image.fromarray(img)\n",
    "    total_image.show()\n",
    "\n",
    "from ultralytics import YOLO        # YOLO v8\n",
    "model = YOLO(\"yolov8n.pt\")          # The model to use for object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Broad_Objects(file, conf = 0.01, iou = 0.4, cutoff_factor = 0.6, cutoff_limit = 0.0004,print_output = False, show_output=False):\n",
    "    import numpy as np\n",
    "    total_images_bounding_box = []\n",
    "    \n",
    "    if type(file)==str:\n",
    "        img = cv2.imread(file)\n",
    "    else:\n",
    "        img = file\n",
    "    width, height = img.shape[:2]\n",
    "    ori_image = img.copy()\n",
    "    results = model(file,conf=conf, iou=iou)  # predict on an image\n",
    "\n",
    "    # NMS\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1 , y1 , x2 , y2 = box.xyxy.detach().numpy()[0]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            confidences.append(box.conf.detach().numpy()[0])\n",
    "\n",
    "    # convert boxes and confidences to numpy array\n",
    "    boxes = np.array(boxes)\n",
    "    confidences = np.array(confidences)\n",
    "\n",
    "    # NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf, iou)\n",
    "    indices = indices.flatten()\n",
    "\n",
    "    for i in indices:\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        area_ratio = abs(x1-x2)*abs(y1-y2)/(width*height)\n",
    "        if print_output:\n",
    "            print(\"area ratio = \", area_ratio)\n",
    "        if (area_ratio<cutoff_factor and area_ratio>cutoff_limit):\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,255), 2)\n",
    "            img = cv2.putText(img, str(area_ratio),( (int(x2), int(y2))), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=2, color = (255,0,0))\n",
    "            if print_output:\n",
    "                print(confidences[i])\n",
    "            total_images_bounding_box.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "        else:\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 3)\n",
    "            img = cv2.putText(img, str(confidences[i]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color = (0,0,255))\n",
    "            if print_output:\n",
    "                print(\"left \",confidences[i])\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target=show_image, args=(img,))\n",
    "        t.start()\n",
    "    return total_images_bounding_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Broad_Objects2(file, conf = 0.01, iou = 0.4, cutoff_factor = 0.6, cutoff_limit = 0.0004,print_output = False, show_output=False):\n",
    "    '''\n",
    "    This function extracts the bounding boxes from the image using YOLO object detection.\n",
    "\n",
    "    parameters - \n",
    "        file - name of the image, or opencv image file\n",
    "        conf - the cofidence threshold for object deection (though it is not a good \n",
    "        practice to keep the confidence threshold to such a low value but because the image background is plain \n",
    "        and the objects detected will most probably be the items, the default value is expreimentally derived and\n",
    "        later an object detection network can be trained for this task)\n",
    "        iou - \n",
    "\n",
    "    return type -\n",
    "        total_images_bounding_box - a list of bounding boxes coordinates representing a particular oject in the image\n",
    "    '''\n",
    "    total_images_bounding_box = []\n",
    "\n",
    "    if type(file) == str:\n",
    "        img = cv2.imread(file)\n",
    "    else:\n",
    "        img = file\n",
    "    width, height = img.shape[:2]\n",
    "    ori_image = img.copy()\n",
    "    results = model(file, conf=conf, iou=iou)  # predict on an image\n",
    "\n",
    "    # NMS\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy.detach().numpy()[0]\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            confidences.append(box.conf.detach().numpy()[0])\n",
    "\n",
    "    # convert boxes and confidences to numpy array\n",
    "    boxes = np.array(boxes)\n",
    "    confidences = np.array(confidences)\n",
    "\n",
    "    # NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf, iou)\n",
    "    indices = indices.flatten()\n",
    "\n",
    "    selected_boxes = []\n",
    "    for i in indices:\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        area_ratio = abs(x1-x2)*abs(y1-y2)/(width*height)\n",
    "\n",
    "        # Check if the current bounding box is fully contained in any of the selected boxes\n",
    "        contained = False\n",
    "        for selected_box in selected_boxes:\n",
    "            if x1 >= selected_box[0] and y1 >= selected_box[1] and x2 <= selected_box[2] and y2 <= selected_box[3]:\n",
    "                contained = True\n",
    "                break\n",
    "\n",
    "        if (area_ratio < cutoff_factor and area_ratio > cutoff_limit) and not contained:\n",
    "            if print_output:\n",
    "                print(\"area ratio = \", area_ratio)\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "            img = cv2.putText(img, str(area_ratio), ((int(x2), int(y2))), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 0, 0))\n",
    "            if print_output:\n",
    "                print(confidences[i])\n",
    "            total_images_bounding_box.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "            selected_boxes.append([x1, y1, x2, y2])\n",
    "        else:\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)\n",
    "            img = cv2.putText(img, str(confidences[i]),( (int(x1), int(y1))), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color = (0,0,255))\n",
    "            if print_output:\n",
    "                print(\"left \",confidences[i])\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target=show_image, args=(img,))\n",
    "        t.start()\n",
    "    return total_images_bounding_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Analyse Get_Broad_Objects\n",
    "# file_name = r'all barcode\\IMG_20220303_173846.jpg'\n",
    "# img_no2 = cv2.imread(file_name)\n",
    "# points = Get_Broad_Objects2(remove_shadows(img_no2), show_output=True)\n",
    "# print(points)\n",
    "# # img = draw_boxes(file_name, points)\n",
    "# t = Thread(target=show_image, args=(img,))\n",
    "# t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Fine_Object(file, point, eps=140, min_samples=40, show_output = False):\n",
    "    \n",
    "    if (type(file)==str):\n",
    "        img = cv2.imread(file)\n",
    "    else:\n",
    "        img = file\n",
    "    x1, y1, x2, y2 = point\n",
    "    img = img[y1:y2, x1:x2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    width,height = img.shape[:2]\n",
    "\n",
    "    output_points = []\n",
    "\n",
    "    # Get coordinates of corners\n",
    "    coords = np.column_stack(np.where(dst > 0.01 * dst.max()))\n",
    "    img_temp = img.copy()\n",
    "    img_temp[dst>0.01*dst.max()]=[255,255,0]\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)\n",
    "\n",
    "    # Get labels for each corner\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    # Draw bounding box around each cluster\n",
    "    for i in range(n_clusters_):\n",
    "        \n",
    "        # Get indexes of corners in current cluster\n",
    "        indexes = np.where(labels == i)\n",
    "\n",
    "        # Get coordinates of corners in current cluster\n",
    "        cluster_coords = coords[indexes]\n",
    "\n",
    "        # Get min and max x and y coordinates\n",
    "        min_x, min_y = np.min(cluster_coords, axis=0)\n",
    "        max_x, max_y = np.max(cluster_coords, axis=0)\n",
    "        if abs((max_x-min_x)*(max_y-min_y))/(width*height)<0.1:\n",
    "            continue\n",
    "        output_points.append([min_y+x1, min_x+y1, max_y+x1, max_x+y1])\n",
    "        # Draw bounding box\n",
    "        # cv2.rectangle(img, (min_y, min_x), (max_y, max_x), (0, 255, 0), 2)\n",
    "        # print(\"area ratio = \",abs((max_x-min_x)*(max_y-min_y))/(width*height))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target=show_image, args=(img,))\n",
    "        t.start()\n",
    "\n",
    "    return output_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check get_fine_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNdraw_barcode(image, show_output = False, save_image_output = False):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect barcodes\n",
    "    barcodes = pyzbar.decode(gray)\n",
    "\n",
    "    # Barcode information to return\n",
    "    information = []\n",
    "\n",
    "    # Iterate over detected barcodes\n",
    "    for barcode in barcodes:\n",
    "        # Extract barcode data and type\n",
    "        barcodeData = barcode.data.decode(\"utf-8\")\n",
    "        barcodeType = barcode.type\n",
    "        \n",
    "        \n",
    "        # Draw barcode bounding box on image\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Info packet to return\n",
    "        information.append([x, y, x+w , y+h, barcodeData])\n",
    "\n",
    "        # Print barcode data and type\n",
    "        # print(\"[INFO] Found {} barcode: {}\".format(barcodeType, barcodeData))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target = show_image, args=(image,))\n",
    "        t.start()\n",
    "    \n",
    "    if (save_image_output):\n",
    "        Image.fromarray(image).save(rf\"Barcode Output/{round(np.random.rand()*93,5)}.png\")\n",
    "\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNdraw_barcode_updated(image, show_output = False, save_image_output = False):\n",
    "    img_ori = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    information = []\n",
    "\n",
    "    # Detect barcodes using pyzbar\n",
    "    barcodes = pyzbar.decode(gray)\n",
    "    for barcode in barcodes:\n",
    "        barcodeData = barcode.data.decode(\"utf-8\")\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        information.append([x, y, x+w , y+h, barcodeData])\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Detect barcodes using Dynamsoft Barcode Reader\n",
    "    BarcodeReader.init_license(\"license_key\")\n",
    "    reader = BarcodeReader()\n",
    "    Image.fromarray(img_ori).save('temporary_image.png')\n",
    "    try:\n",
    "        text_results = reader.decode_file('temporary_image.png')\n",
    "        if text_results != None:\n",
    "            for text_result in text_results:\n",
    "                text = text_result.barcode_text\n",
    "                points = text_result.localization_result.localization_points\n",
    "                pts = np.array(points, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                cv2.polylines(image, [pts], True, (255, 0, 0), 5)\n",
    "                x, y, x2, y2 = pts[0][0][0], pts[0][0][1], pts[2][0][0], pts[2][0][1]\n",
    "                # Check if the barcode information is already in the list\n",
    "                if [x, y, x2, y2, text] not in information:\n",
    "                    information.append([x, y, x2, y2, text])\n",
    "    except BarcodeReaderError as bre:\n",
    "        print(bre)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if (show_output):\n",
    "        t = Thread(target = show_image, args=(image,))\n",
    "        t.start()\n",
    "    if (save_image_output):\n",
    "        Image.fromarray(image).save(rf\"Barcode Output/{round(np.random.rand()*93,5)}.png\")\n",
    "\n",
    "    return information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(bbox1, bbox2):\n",
    "    x1, y1, x2, y2 = bbox1\n",
    "    x3, y3, x4, y4 = bbox2\n",
    "\n",
    "    # find the coordinates of the intersection rectangle\n",
    "    x_left = max(x1, x3)\n",
    "    y_top = max(y1, y3)\n",
    "    x_right = min(x2, x4)\n",
    "    y_bottom = min(y2, y4)\n",
    "\n",
    "    # check if there is an overlap\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bbox1_area = (x2 - x1) * (y2 - y1)\n",
    "    bbox2_area = (x4 - x3) * (y4 - y3)\n",
    "\n",
    "    # calculate the IoU\n",
    "    iou = intersection_area / float(bbox1_area + bbox2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def getNdraw_barcode_updated2(image, iou_threshold=0.4, show_output=False, save_image_output=False):\n",
    "    img_ori = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    information = []\n",
    "\n",
    "    # Detect barcodes using pyzbar\n",
    "    barcodes = pyzbar.decode(gray)\n",
    "    for barcode in barcodes:\n",
    "        barcodeData = barcode.data.decode(\"utf-8\")\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        information.append([x, y, x+w , y+h, barcodeData])\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Detect barcodes using Dynamsoft Barcode Reader\n",
    "    BarcodeReader.init_license(\"license_key\")\n",
    "    reader = BarcodeReader()\n",
    "    Image.fromarray(img_ori).save('temporary_image.png')\n",
    "    try:\n",
    "        text_results = reader.decode_file('temporary_image.png')\n",
    "        if text_results != None:\n",
    "            for text_result in text_results:\n",
    "                text = text_result.barcode_text\n",
    "                points = text_result.localization_result.localization_points\n",
    "                pts = np.array(points, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                x, y, x2, y2 = pts[0][0][0], pts[0][0][1], pts[2][0][0], pts[2][0][1]\n",
    "\n",
    "                # Check if the barcode information is already in the list\n",
    "                if [x, y, x2, y2, text] not in information:\n",
    "                    # Calculate IoU for the current bounding box from Dynamsoft and existing bounding boxes from pyzbar\n",
    "                    overlap = False\n",
    "                    for info in information:\n",
    "                        x1, y1, x2_, y2_, _ = info\n",
    "                        boxA = [x1, y1, x2_, y2_]\n",
    "                        boxB = [x, y, x2, y2]\n",
    "                        iou = calculate_iou(boxA, boxB)\n",
    "                        if iou >= iou_threshold:\n",
    "                            overlap = True\n",
    "                            break\n",
    "                    if not overlap:\n",
    "                        information.append([x, y, x2, y2, text])\n",
    "                        cv2.polylines(image, [pts], True, (255, 0, 0), 5)\n",
    "    except BarcodeReaderError as bre:\n",
    "        print(bre)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if show_output:\n",
    "        t = Thread(target=show_image, args=(image,))\n",
    "        t.start()\n",
    "\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(bbox1, bbox2):\n",
    "    x1, y1, x2, y2 = bbox1\n",
    "    x3, y3, x4, y4 = bbox2\n",
    "\n",
    "    # find the coordinates of the intersection rectangle\n",
    "    x_left = max(x1, x3)\n",
    "    y_top = max(y1, y3)\n",
    "    x_right = min(x2, x4)\n",
    "    y_bottom = min(y2, y4)\n",
    "\n",
    "    # check if there is an overlap\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bbox1_area = (x2 - x1) * (y2 - y1)\n",
    "    bbox2_area = (x4 - x3) * (y4 - y3)\n",
    "\n",
    "    # calculate the IoU\n",
    "    iou = intersection_area / float(bbox1_area + bbox2_area - intersection_area)\n",
    "    return iou\n",
    "    \n",
    "def getNdraw_barcode_updated3(image, iou_threshold=0.3, show_output=False, save_image_output=False, only_barcode=False):\n",
    "    img_ori = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    information = []\n",
    "\n",
    "    # Detect barcodes using Dynamsoft Barcode Reader\n",
    "    BarcodeReader.init_license(\"license_key\")\n",
    "    reader = BarcodeReader()\n",
    "    Image.fromarray(img_ori).save('temporary_image.png')\n",
    "    try:\n",
    "        text_results = reader.decode_file('temporary_image.png')\n",
    "        if text_results != None:\n",
    "            for text_result in text_results:\n",
    "                text = text_result.barcode_text\n",
    "                points = text_result.localization_result.localization_points\n",
    "                if (text_result.barcode_format_string!='EAN_13' and only_barcode):\n",
    "                    continue\n",
    "                pts = np.array(points, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                x, y, w, h = cv2.boundingRect(pts)\n",
    "                x2, y2 = x + w, y + h\n",
    "                # x, y, x2, y2 = pts[0][0][0], pts[0][0][1], pts[2][0][0], pts[2][0][1]\n",
    "                \n",
    "\n",
    "                img_other = image.copy()[y:y2,x:x2]\n",
    "                \n",
    "                # Check if the barcode information is already in the list\n",
    "                if [x, y, x2, y2, text] not in information:\n",
    "                    information.append([x, y, x2, y2, text])\n",
    "                    cv2.polylines(image, [pts], True, (255, 0, 0), 2)\n",
    "\n",
    "    except BarcodeReaderError as bre:\n",
    "        print(bre)\n",
    "\n",
    "    # Detect barcodes using pyzbar\n",
    "    barcodes = pyzbar.decode(gray)\n",
    "    for barcode in barcodes:\n",
    "        barcodeData = barcode.data.decode(\"utf-8\")\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        boxA = [x, y, x+w, y+h]\n",
    "        if (barcode.type!=\"EAN13\" and only_barcode):\n",
    "            continue\n",
    "\n",
    "        # Check if the barcode information is already in the list\n",
    "        if [x, y, x+w, y+h, barcodeData] not in information:\n",
    "            # Calculate IoU for the current bounding box from pyzbar and existing bounding boxes from Dynamsoft\n",
    "            overlap = False\n",
    "            for info in information:\n",
    "                x1, y1, x2_, y2_, _ = info\n",
    "                boxB = [x1, y1, x2_, y2_]\n",
    "                iou = calculate_iou(boxA, boxB)\n",
    "                if iou >= iou_threshold:\n",
    "                    overlap = True\n",
    "                    info[4]=barcodeData\n",
    "                    break\n",
    "            if not overlap:\n",
    "                information.append([x, y, x+w, y+h, barcodeData])\n",
    "                image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if show_output:\n",
    "        t = Thread(target=show_image, args=(image,))\n",
    "        t.start()\n",
    "\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # convert the coordinates of the two boxes from tuples to polyggon objects\n",
    "    listA = []\n",
    "    listB = []\n",
    "    for one in boxA[0]:\n",
    "        listA.append(one[0])\n",
    "    for one in boxB[0]:\n",
    "        listB.append(one[0])\n",
    "    polyA = Polygon(listA)\n",
    "    polyB = Polygon(listB)\n",
    "    \n",
    "    # calculate the intersection of the two polyggon objects\n",
    "    inter = polyA.intersection(polyB).area\n",
    "    \n",
    "    # calculate the union of the two polyggon objects\n",
    "    union = polyA.union(polyB).area\n",
    "    \n",
    "    # calculate the IoU\n",
    "    iou = inter / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def getNdraw_barcode_updated4(image, iou_threshold=0.1, show_output=False, save_image_output=False, only_barcode=False):\n",
    "    img_ori = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    information = []\n",
    "\n",
    "    # Detect barcodes using Dynamsoft Barcode Reader\n",
    "    BarcodeReader.init_license(\"license_key\")\n",
    "    reader = BarcodeReader()\n",
    "    Image.fromarray(img_ori).save('temporary_image.png')\n",
    "    try:\n",
    "        text_results = reader.decode_file('temporary_image.png')\n",
    "        if text_results != None:\n",
    "            for text_result in text_results:\n",
    "                text = text_result.barcode_text\n",
    "                points = text_result.localization_result.localization_points\n",
    "                if (text_result.barcode_format_string!='EAN_13' and only_barcode):\n",
    "                    continue\n",
    "                pts = np.array(points, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                x, y, x2, y2 = pts[0][0][0], pts[0][0][1], pts[2][0][0], pts[2][0][1]\n",
    "\n",
    "                img_other = image.copy()[y:y2,x:x2]\n",
    "                \n",
    "                # Check if the barcode information is already in the list\n",
    "                information_dict = {'rect_pts': pts, 'barcodeData': text}\n",
    "                found = False\n",
    "                for i in information:\n",
    "                    if np.array_equal(i, information_dict):\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "                if not found:\n",
    "                    \n",
    "                    information.append(information_dict)\n",
    "                    cv2.polylines(image, [pts], True, (255, 0, 0), 2)\n",
    "\n",
    "    except BarcodeReaderError as bre:\n",
    "        print(bre)\n",
    "\n",
    "    # Detect barcodes using pyzbar\n",
    "    barcodes = pyzbar.decode(gray)\n",
    "    for barcode in barcodes:\n",
    "        barcodeData = barcode.data.decode(\"utf-8\")\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        boxA = [x, y, x+w, y+h]\n",
    "        if (barcode.type!=\"EAN13\" and only_barcode):\n",
    "            continue\n",
    "        rect_points = [(x, y), (x, y+h), (x+w, y+h), (x+w, y)]\n",
    "        rect_pts = np.array(rect_points, np.int32)\n",
    "        rect_pts = rect_pts.reshape((-1, 1, 2))\n",
    "        # Check if the barcode information is already in the list\n",
    "        information_dict = {'rect_pts': rect_pts, 'barcodeData': barcodeData}\n",
    "        found = False\n",
    "        for i in information:\n",
    "            if np.array_equal(i, information_dict):\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            # Calculate IoU for the current bounding box from pyzbar and existing bounding boxes from Dynamsoft\n",
    "            overlap = False\n",
    "            for info in information:\n",
    "                points = info['rect_pts']\n",
    "                boxB = [points]\n",
    "                iou = calculate_iou(boxB, [rect_pts])\n",
    "                if iou >= iou_threshold:\n",
    "                    overlap = True\n",
    "                    info['barcodeData']=barcodeData\n",
    "                    break\n",
    "            if not overlap:\n",
    "                information_dict = {'rect_pts': rect_pts, 'barcodeData': barcodeData}\n",
    "                information.append(information_dict)\n",
    "                image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    return information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = r'all barcode\\IMG_20220303_173611.jpg'\n",
    "img_current = cv2.imread(image_file_name)\n",
    "outer_info = getNdraw_barcode_updated4(img_current, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temp block\n",
    "import cv2\n",
    "img = cv2.imread(r\"Input_Images\\all barcode\\IMG_20220303_173611.jpg\")\n",
    "getNdraw_barcode_updated4(img, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r'all barcode\\IMG_20220303_173846.jpg'\n",
    "boxes = Get_Broad_Objects(file,show_output=False)\n",
    "fine_boxes = []\n",
    "for box in boxes:\n",
    "    # print(box)\n",
    "    fine_boxes.append(Get_Fine_Object(file,box, show_output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(file)\n",
    "# show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "for box in boxes:\n",
    "    \n",
    "    img_to_send = img[box[1]:box[3], box[0]:box[2]]\n",
    "    info.append(getNdraw_barcode(img_to_send, False, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the Barcodes on the image\n",
    "def plot_bar_code_data(img, info, boxes):\n",
    "    print(len(info), len(boxes))\n",
    "    unique_codes = {}\n",
    "    img2 = img.copy()\n",
    "    for i in range(len(info)):\n",
    "        if (len(info[i])>0):\n",
    "            if (len(info[i][0])!=5):\n",
    "                print(\"No Barcode Found\")\n",
    "                continue\n",
    "            box_x1, box_y1, box_x2, box_y2 = boxes[i]\n",
    "            code_x1, code_y1, code_x2 , code_y2, code_data = info[i][0]\n",
    "            final_coordi_x1, final_coordi_y1, final_coordi_x2, final_coordi_y2 = box_x1+code_x1, \\\n",
    "            box_y1+code_y1, box_x1+ code_x2, box_y1+ code_y2\n",
    "\n",
    "            img2 = cv2.rectangle(img2, (final_coordi_x1, final_coordi_y1), \n",
    "            (final_coordi_x2, final_coordi_y2), (255,0,255), 2)\n",
    "\n",
    "            if (code_data in unique_codes):\n",
    "                unique_codes[code_data]+=1\n",
    "            else:\n",
    "                unique_codes[code_data]=1\n",
    "\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # t = Thread(target=show_image, args=(img2,))\n",
    "    # t.start()\n",
    "\n",
    "    return unique_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_code_data(img, info, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_value(list_of_coord):\n",
    "    areas = 0\n",
    "    index = 0\n",
    "    for coord in list_of_coord:\n",
    "        if (len(coord)==4):\n",
    "            x1,y1,x2,y2 = coord\n",
    "            areas += abs((x2-x1)*(y2-y1))\n",
    "            index +=1\n",
    "    if (index==0):\n",
    "        return float('inf')\n",
    "    return areas/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlap(box1, box2):\n",
    "    # get the coordinates of the two boxes\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "    \n",
    "    # check if the boxes overlap vertically\n",
    "    if x1 > x2g or x2 < x1g:\n",
    "        return False\n",
    "    \n",
    "    if y1g > y2 or y2g < y1:\n",
    "        return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow of The Algorithm\n",
    "\n",
    "    Step 1 : Get Outer Boxes of the objects from the Image, bounding Box coordinates are returned.\n",
    "\n",
    "    Step 2 : Get the inner Boxes of the objects from the Image, after cropping the individual outer boxes.\n",
    "\n",
    "    Step 3 : Draw Black bounding box on all the inner objects. i.e. inner boxes black.\n",
    "\n",
    "    Step 4 : Pass individual objects to identify barcode. Bounding boxes of bar code are returned. If no bar code found empty list is returned. If so, corresponding object is red coloured.\n",
    "\n",
    "    Step 5 : If bar code found color it blue and return the unique list map specifying number of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = r'all barcode\\IMG_20220303_175539.jpg'\n",
    "def start_func(image_file_name, show_out = False, use_outer = False, check_directly=False, direct_check_threshold=5):\n",
    "    image = cv2.imread(image_file_name)\n",
    "\n",
    "    # Getting outer boxes\n",
    "    list_of_outer_boxes = Get_Broad_Objects2(image_file_name, cutoff_factor=0.6)\n",
    "\n",
    "    # Getting inner boxes\n",
    "    list_of_inner_boxes = []\n",
    "    for box in list_of_outer_boxes:\n",
    "        list_of_inner_boxes.append(Get_Fine_Object(image_file_name,box))\n",
    "\n",
    "    cordinates_of_objects = []\n",
    "    # cordinates_of_objects = list_of_outer_boxes       #if inner objects not identified correctly\n",
    "\n",
    "    # Drawing black bounding boxes\n",
    "    if (use_outer):\n",
    "        # print(list_of_outer_boxes)\n",
    "        for index in range(len(list_of_outer_boxes)):\n",
    "            x1, y1 , x2, y2 = list_of_outer_boxes[index]\n",
    "            image = cv2.rectangle(image, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,0), 2)\n",
    "            cordinates_of_objects.append([x1, y1 , x2, y2])\n",
    "    else:\n",
    "        # print(list_of_inner_boxes)\n",
    "        for index in range(len(list_of_inner_boxes)):\n",
    "            for k in list_of_inner_boxes[index]:\n",
    "                x1, y1 , x2, y2 = k\n",
    "                image = cv2.rectangle(image, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,0), 2)\n",
    "                cordinates_of_objects.append([x1, y1 , x2, y2])\n",
    "\n",
    "    # Getting bar code data from individual object\n",
    "    info = []\n",
    "    for box in cordinates_of_objects:\n",
    "        img_to_send = image[box[1]:box[3], box[0]:box[2]]\n",
    "        info.append(getNdraw_barcode_updated3(img_to_send, iou_threshold=0.2))\n",
    "\n",
    "    # Getting global coordinates of bar code\n",
    "    global_bar_codecordinates = []\n",
    "    for i in range(len(info)):\n",
    "        if (len(info[i])==0):\n",
    "            # global_bar_codecordinates.append([])\n",
    "            image = cv2.rectangle(image, (int(cordinates_of_objects[i][0]),int(cordinates_of_objects[i][1])), \n",
    "            (int(cordinates_of_objects[i][2]),int(cordinates_of_objects[i][3])), (0,0,255), 2)\n",
    "            continue\n",
    "        for coord in info[i]:\n",
    "            x1 , y1 , x2 , y2 = cordinates_of_objects[i][0]+ coord[0], cordinates_of_objects[i][1]+ coord[1] , \\\n",
    "            cordinates_of_objects[i][0]+ coord[2],cordinates_of_objects[i][1]+ coord[3]\n",
    "            global_bar_codecordinates.append([x1 , y1 , x2 , y2])\n",
    "\n",
    "    # Getting the unique dictionary of the barcodes\n",
    "    Objects = {}\n",
    "    for bar_code_info in info:\n",
    "        for elements in bar_code_info:\n",
    "            if (elements[4] in Objects):\n",
    "                Objects[elements[4]]+=1\n",
    "            else:\n",
    "                Objects[elements[4]]=1\n",
    "\n",
    "    \"\"\" A slightly risky feature that will find if any barcode has been left out, by finding it directly from image.\n",
    "    It will check if atleast 1 instance of the barcode is present in the image, if not draw blue box around them\n",
    "    The correspoinding object may not have black bounding box.\"\"\"\n",
    "    if (check_directly):\n",
    "        \n",
    "        img_current = cv2.imread(image_file_name)\n",
    "        outer_info = getNdraw_barcode_updated3(img_current)\n",
    "        for daa in outer_info:\n",
    "            # if (daa[4] not in Objects):\n",
    "            x1 , y1 , x2 , y2 = daa[:4]\n",
    "            \n",
    "            overlap = False\n",
    "            for g_barcode in global_bar_codecordinates:\n",
    "                # if (len(g_barcode)==4):\n",
    "                x1g, y1g, x2g, y2g = g_barcode\n",
    "                \n",
    "                if is_overlap([x1 , y1 , x2 , y2],[x1g, y1g, x2g, y2g]):\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if overlap==False:\n",
    "                image = cv2.rectangle(image, (x1,y1), (x2,y2), (255,255,0),2 )\n",
    "                global_bar_codecordinates.append([x1, y1, x2, y2])\n",
    "                Objects[daa[4]]=1\n",
    "                if (daa[4] in Objects):\n",
    "                    Objects[daa[4]]+=1\n",
    "                else:\n",
    "                    Objects[daa[4]]=1\n",
    "\n",
    "\n",
    "    if (show_out):\n",
    "        t = Thread(target=show_image, args=(cv2.cvtColor(image,cv2.COLOR_BGR2RGB),))\n",
    "        t.start()\n",
    "    print(Objects)\n",
    "\n",
    "    return np.array([image, global_bar_codecordinates],dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = r\"Input_Images\\all barcode\\IMG_20220303_173611.jpg\"\n",
    "out = start_func(image_file_name, show_out=True, check_directly=True)\n",
    "img = out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file_name = r'all barcode\\IMG_20220303_173611.jpg'\n",
    "# img_current = cv2.imread(image_file_name)\n",
    "# outer_info = getNdraw_barcode_updated4(img_current, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detected_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_current = cv2.imread(image_file_name)\n",
    "coords = out[1]\n",
    "for cor in coords:\n",
    "    img_current = cv2.rectangle(img_current, (cor[0],cor[1]), (cor[2],cor[3]), (0,0,0), 3)\n",
    "\n",
    "t = Thread(target=show_image, args=(img_current,))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# dir = r''\n",
    "dirs = [r'all barcode', r'missing and partial barcode', r'missing barcode',r'partial barcode']\n",
    "out_box = 'OutputFinal'\n",
    "for dir in dirs:\n",
    "    for image in os.listdir(dir):\n",
    "        file_name = os.path.join(dir, image)\n",
    "        ims = start_func(file_name, check_directly=True)[0]\n",
    "        file_out = os.path.join(out_box, image)\n",
    "        cv2.imwrite(file_out, ims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c754d8008c5f8560e4adf341ebf96f62d30db323e3ac43f60a1cb4dab6d757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
